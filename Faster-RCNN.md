# Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks

Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun
(https://arxiv.org/pdf/1506.01497.pdf, 2015)

### TL;DR
- Builds on R-CNN and Fast-RCNN by proposing a Region Proposal Network (RPN) to speed up region proposals, which was the main bottleneck before. Merges RPN and Fast R-CNN into a single network, producing SOTA on VOC07, 12, & MS COCO datasets.

### Main Contributions
- Main contribution is improving upon Fast R-CNN by proposing a new Region proposal network. RPNs are effective & accurate for region proposals.
- Sharing the proposals with the down-stream Fast-RCNN network makes this step almost cost-free.
- Improves overall object detection accuracy & produces SOTA results.

**My takeaway:** RPN is a replacement to selective search (and addition to Fast R-CNN), optimizing region proposals & produces SOTA object detection accuracy.

### Relevant Architecture

<img src="https://github.com/sviswana/deeplearning-paper-summaries/blob/master/paper-imgs/faster-rcnn.png" width="30%">

- There are two modules:
  1. Deep FCNN that proposes regions.
  2. Traditional Fast R-CNN detector (see my summary for Fast R-CNN paper [**here**](https://github.com/sviswana/deeplearning-paper-summaries/blob/master/FastR-CNN.md))
  But these are in a single, unified network for object detection.
- RPN takes image and outputs set of rectangular object proposals, with score for each object. Proposals are generated by sliding small network over convolutional feature map output (n x n window) -> mapped to lower-dimensional feature -> fed to two FC layers (bbox regression layer + box classification layer).
- For each sliding window location, many region proposals are predicted. These are relative to reference boxes, called anchors. Anchors are centered at sliding window, and 9 anchors are used for each proposal (various scale / aspect ratios)
- Region proposals -> RoI pooling layer -> classify image within the proposed region and predict offset values for bounding boxes.

#### Certain training details
- RPN can be trained end-to-end with back-prop & SGD, and layers are initialized by pretraining ImageNet model.
- Alternating training, where RPN and Fast R-CNN are trained alternatively. Approximate joint training is also tested, where RPN & Fast R-CNN networks are merged.

### Results
- SOTA results on VOC 2007 & 2012 datasets. RPN with Fast R-CNN results in 59.9% in mAP.
- MS COCO dataset with VGG-16 model gives 42.7% mAP.

### Future Work
- Future work can definitely be done in optimizing joint training (without being approximate) for faster training.
